---
title: "Project 2: projectpackage Tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{projectpackage Tutorial}

  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Introduction: This is a R package that utilized cross-validation algorithm and hypothesis testing mechanism to produce prediction and inference. It includes four functions: my_t.test, my_lm, my_knn_cv, my_rf_cv. In regards to installation instruction, please see the installation section below. The documentation of each function can be accessed through ?function_name(). If you have any question, feel free to reach out to us: harperzhu@yahoo.com , sz94@uw.edu
```{r}

#instructions for how to install your package from Github
#install.packages("devtools")
#devtools::install_github("harperzhu/projectpackage")
library(projectpackage)

```


```{r}
#A tutorial for my_t.test
#hypothesis: mean of the lifeExp data from my_gapminder equals to 60
#alternative hypothesis: mean of the lifeExp data from my_gapminder does not equal to 60
my_t_test(x=(my_gapminder$lifeExp),alternative="two sided",mu = 60)


#hypothesis: mean of the lifeExp data from my_gapminder equals to 60
#alternative hypothesis: mean of the lifeExp data from my_gapminder is smaller than 60
my_t_test(x=(my_gapminder$lifeExp),alternative="less",mu = 60)

#hypothesis: mean of the lifeExp data from my_gapminder equals to 60
#alternative hypothesis: mean of the lifeExp data from my_gapminder is larger than 60
my_t_test(x=(my_gapminder$lifeExp),alternative="greater",mu = 60)

```
For the first t-test, we observe P = 0.09322877. Therefore we conclude that we have sufficient evidence to reject the null hypothesis and conclude that the true mean life expectancy is not equal to 60.

For the second t-test, we observe P = 0.9533856 Therefore we conclude that we do not have sufficient evidence to reject the null hypothesis. Therefore, we cannot conclude that the true mean life expectancy is smaller than 60.

For the third t-test, we observe P = 0.04661438. Therefore we conclude that we  have sufficient evidence to reject the null hypothesis and conclude that the true mean life expectancy is greater than 60.
```{r}
#A tutorial for my_lm
#Demonstrate a regression using lifeExp as your response variable and gdpPercap and continent as explanatory variables
lm_fit <- my_lm(lifeExp ~gdpPercap + continent, data = my_gapminder)

#Write the hypothesis test associated with the gdpPercap coefficient.
my_t_test(x= my_gapminder$gdpPercap, alternative="less", mu = 4.452704e-04)

#predict the fitted values 
my_estimate <- lm_fit$Estimate
my_matrix <- model.matrix(lifeExp ~gdpPercap + continent, data = my_gapminder)
y_hat <- my_matrix %*% as.matrix(my_estimate)
my_df <- data.frame("actual" = my_gapminder$lifeExp, "fitted" = y_hat, "continent" = my_gapminder$continent)
#plot the Actual vs. Fitted values.
library(ggplot2)
x <- my_gapminder$gdpPercap
y <- my_df$y_hat
fitting_plot <- ggplot(my_df, aes(x=x, y=y, color = continent)) +
        ggtitle(label = "Actual vs Fitted Values") +
        geom_point(aes(x = actual, y = fitted)) +
        xlab(label = "Actual value") +
        ylab(label = "Fitted value") +
        geom_abline(slope = 1, intercept = 0) +
        theme_bw() 
        # geom_line(aes(x = x, y = fitted, col="Fitted value",lwd = 0.1)) 
        # labs(subtitle = paste("Testing Error:", round(test_err_k, 3))) +
        # theme_bw()
fitting_plot
```
1. interpret the gdpPercap coefficient: 
The coefficient of gdpPercap is 4.452704e-04. That would means that for every one unit of increase in gdp Per capital, there will be 4.452704e-04 increase in life Expectancy.
2. interpret the results the gdpPercap hypothesis test using a p-value cut-off of Î±=0.05.:
p-value is 3.017639e-161, which is significantly smaller than 0.05.Therefore, we have enough evidence to reject that the null hypothesis that the mu of gdpPerCap is 4.452704e-04.
3.Interpret the Actual vs. Fitted values plot:
The model is not optimal. As the x-axis represents the actual lines, and the y axis represents the fitted value, the slope of the line would represent the percent of precision of the fitted value to the actual values. Here, the slope of the graph does not appear to be straight, which means that this model fit is not optimal. The graph shows that the higher the actual values are, the higher precision.  


```{r}
#A tutorial for my_knn_cv using my_penguins.
my_table <- data.frame()
my_penguins <- na.omit(my_penguins)
for(i in 1:10) {
  my_result <- my_knn_cv(train = my_penguins, cl = my_penguins$species, k_nn = i, k_cv = 5 )
  my_table[1,i] <- my_result$cv_err
  my_table[2,i] <- sum(as.numeric(my_penguins$species != my_result$class)) / nrow(my_penguins)
}
rownames(my_table) <- c("cv_err", "training_err")
colnames(my_table) <- c("k_nn = 1", "k_nn = 2", "k_nn = 3", "k_nn = 4", "k_nn = 5", "k_nn = 6", "k_nn = 7", "k_nn = 8", "k_nn = 9", "k_nn = 10")
```

According to the results in the table we can see that when k_nn = 1, we have both the smallest cv error and the training error, so I think k_nn = 1 is the best model when k_cv = 5. 

Cross validation is a statistical method that used to check how accurately our model can predict the result. This method is very useful since it test the model multiple time by using different parts of the same dataset, which is vert efficient.

```{r}
#A tutorial for my_rf_cv
penguins <- my_penguins
library(randomForest)
#Calculate CV estimated MSE when k = 2
my_table_1 <- data.frame()
for(i in 1:30) {
  result <- my_rf_cv(k = 2)
  my_table_1[i,1] <- unlist(result)
}
colnames(my_table_1) <- c("MSE")
rownames(my_table_1) <- c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30")
#Calculate CV estimated MSE when k = 5
my_table_2 <- data.frame()
for(i in 1:30) {
  result <- my_rf_cv(k = 5)
  my_table_2[i,1] <- unlist(result)
}
colnames(my_table_2) <- c("MSE")
rownames(my_table_2) <- c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30")
#Calculate CV estimated MSE when k = 10
my_table_3 <- data.frame()
for(i in 1:30) {
  result <- my_rf_cv(k = 10)
  my_table_3[i,1] <- unlist(result)
}
colnames(my_table_3) <- c("MSE")
rownames(my_table_3) <- c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30")

```



```{r}
#Generate a boxplot of MSE for multiple values of k.
folds <- rep(c(2, 5, 10), each = 30) %>% as.factor()
all_table <- rbind(my_table_1, my_table_2, my_table_3)
df <- data.frame(all_table, folds)
ggplot(data = df,
       aes(    x = unlist(folds),
               y = unlist(all_table),
               group = unlist(folds),
               fill = folds
       )) +
        geom_boxplot() +
        xlab("folds") +
        ylab("MSE") +
        labs("Misclassification Errors with different number of folds") +
        theme_bw() +
        theme(
                plot.title = element_text(hjust = 0.5, face = "bold"),
                axis.text.x = element_text(
                        angle = 45,
                        hjust = 1,
                        vjust = 1
                ),
                panel.spacing.x = unit(0.75, "cm")
        ) +
        scale_fill_brewer(
                type = "seq",
                palette = 1,
                direction = 1,
                aesthetics = "fill"
        )

        
```

```{r}
#Calculating the cverr and the MSE and put they into table for 3 different value of k.
average_cverr_2 <- mean(as.numeric(my_table_1[,1]))
sd_cverr_2 <- sd(as.numeric(my_table_1[,1]))
average_cverr_5 <- mean(as.numeric(my_table_2[,1]))
sd_cverr_5 <- sd(as.numeric(my_table_2[,1]))
average_cverr_10 <- mean(as.numeric(my_table_3[,1]))
sd_cverr_10 <- sd(as.numeric(my_table_3[,1]))
row_1 <- cbind(average_cverr_2, sd_cverr_2)
row_2 <- cbind(average_cverr_5, sd_cverr_5)
row_3 <- cbind(average_cverr_10, sd_cverr_10)
cv_table <- rbind(row_1, row_2, row_3)
rownames(cv_table) <- c("k = 2", "k = 5", "k = 10")
colnames(cv_table) <- c("average", "sd")
cv_table
```
We can see from the table and the boxplot, the average and the standard deviation of ev_err become smaller as the value of k gets larger. This is because as the k gets larger, we test our model for more times, so that it becomes more accurate. Thus the values of cv_err get smaller.
